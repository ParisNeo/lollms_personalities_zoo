{
    "chunks": {
        "web_11.txt_chunk_1": {
            "document_id": "web_11.txt",
            "chunk_index": 1,
            "chunk_text": "# LoLLMs Client Library\nLoLLMs Client is a Python library for interacting with the LoLLMs generate endpoint. This library simplifies the process of sending POST requests to the endpoint and handling responses.\n## Table of Contents\n1. [Installation](#installation)\n2. [Usage](#usage)\n3. [API Reference](#api-reference)\n4. [Contributing](#contributing)\n5. [License](#license)\n## Installation\nTo install the LoLLMs Client library, use pip:\n```bash\npip install lollms_client\n```\n## Usage\nHere's an example of how to use the LoLLMs Client library:\n```python\nfrom lollms_client import generate_text\nresponse = generate_text(host_address=\"http://localhost:9600\", prompt=\"Your prompt here\")\nprint(response)\n```\n## API Reference\n### generate_text\nSends a POST request to the specified LoLLMs generate endpoint.\n```python\ngenerate_text(\n    host_address: str,\n    prompt: str,\n    model_name: Optional[str] = None,\n    personality: int = -1,\n    n_predict: int = 1024,\n    stream: bool = False,\n    temperature: float = 0.7,\n    top_k: int = 50,\n    top_p: float = 0.95,\n    repeat_penalty: float = 0.8,\n    repeat_last_n: int = 40,\n    seed: Optional[int] = None,\n    n_threads: int = 8\n)\n```\n#### Parameters\n- `host_address` (str): The host address of the LoLLMs generate endpoint (e.g., 'http://localhost:9600').\n- `prompt` (str): The prompt to be sent to the LoLLMs generate endpoint.\n- `model_name` (Optional[str]): The name of the model to be used (default: None).\n- `personality` (int): The personality to be used (default: -1).\n- `n_predict` (int): The number of tokens to predict (default: 1024).\n- `stream` (bool): Whether to stream the response (default: False).\n- `temperature` (float): The temperature for sampling (default: 0.1).\n- `top_k` (int): The number of top choices for sampling (default: 50).\n- `top_p` (float): The cumulative probability for top-p sampling (default: 0.95).\n- `repeat_penalty` (float): The penalty for repeating previous tokens (default: 0.8).\n- `repeat_last_n` (int): The number of previous tokens to consider for repeat penalty (default: 40).\n- `seed` (Optional[int]): The seed for random number generation (default: None).\n- `n_threads` (int): The number of threads to use for token prediction (default: 8).\n#### Returns\n- If the request is successful, the function returns the response text.\n- If the request fails, the function returns a dictionary with the status set to False and the error message in the response: `{\"status\": False, \"error\": str(ex)}`.\n## Contributing\nContributions are welcome! If you'd like to contribute to this project, please open a pull request with your proposed changes.\n## License\nLoLLMs Client is released under the [Apache 2.0 License](LICENSE).\n.",
            "embeddings": {
                "__numpy_array__": true,
                "data": [
                    [
                        0.04096159602595203,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.10240399006488006,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.22528877814273615,
                        0.020480798012976014,
                        0.10240399006488006,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.08192319205190406,
                        0.12288478807785608,
                        0.1638463841038081,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.08192319205190406,
                        0.08192319205190406,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.06144239403892804,
                        0.24576957615571215,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.10240399006488006,
                        0.10240399006488006,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.18432718211678412,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.08192319205190406,
                        0.10240399006488006,
                        0.18432718211678412,
                        0.020480798012976014,
                        0.08192319205190406,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.06144239403892804,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.10240399006488006,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.08192319205190406,
                        0.020480798012976014,
                        0.10240399006488006,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.06144239403892804,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.04096159602595203,
                        0.14336558609083208,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.6349047384022564,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.3072119701946402,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.06144239403892804,
                        0.04096159602595203,
                        0.020480798012976014,
                        0.020480798012976014,
                        0.06144239403892804,
                        0.020480798012976014,
                        0.04096159602595203
                    ]
                ]
            }
        }
    },
    "infos": {
        "vectorization_method": "tfidf_vectorizer"
    },
    "vectorizer": {
        "vocabulary": {
            "lollms": 56,
            "client": 16,
            "library": 52,
            "is": 51,
            "python": 85,
            "for": 32,
            "interacting": 50,
            "with": 128,
            "the": 113,
            "generate": 35,
            "endpoint": 25,
            "this": 114,
            "simplifies": 104,
            "process": 80,
            "of": 66,
            "sending": 100,
            "post": 74,
            "requests": 94,
            "to": 116,
            "and": 7,
            "handling": 38,
            "responses": 96,
            "table": 110,
            "contents": 18,
            "installation": 48,
            "usage": 123,
            "api": 9,
            "reference": 87,
            "contributing": 20,
            "license": 53,
            "install": 47,
            "use": 124,
            "pip": 72,
            "bash": 11,
            "lollms_client": 57,
            "here": 39,
            "an": 6,
            "example": 28,
            "how": 42,
            "from": 33,
            "import": 45,
            "generate_text": 36,
            "response": 95,
            "host_address": 41,
            "http": 43,
            "localhost": 55,
            "9600": 4,
            "prompt": 82,
            "your": 130,
            "print": 78,
            "sends": 101,
            "request": 93,
            "specified": 105,
            "str": 107,
            "model_name": 60,
            "optional": 68,
            "none": 64,
            "personality": 71,
            "int": 49,
            "n_predict": 61,
            "1024": 0,
            "stream": 108,
            "bool": 13,
            "false": 30,
            "temperature": 111,
            "float": 31,
            "top_k": 120,
            "50": 2,
            "top_p": 121,
            "95": 3,
            "repeat_penalty": 91,
            "repeat_last_n": 90,
            "40": 1,
            "seed": 99,
            "n_threads": 62,
            "parameters": 69,
            "host": 40,
            "address": 5,
            "be": 12,
            "sent": 102,
            "name": 63,
            "model": 59,
            "used": 125,
            "default": 23,
            "number": 65,
            "tokens": 118,
            "predict": 75,
            "whether": 127,
            "sampling": 98,
            "top": 119,
            "choices": 15,
            "cumulative": 22,
            "probability": 79,
            "penalty": 70,
            "repeating": 92,
            "previous": 77,
            "consider": 17,
            "repeat": 89,
            "random": 86,
            "generation": 37,
            "threads": 115,
            "token": 117,
            "prediction": 76,
            "returns": 97,
            "if": 44,
            "successful": 109,
            "function": 34,
            "text": 112,
            "fails": 29,
            "dictionary": 24,
            "status": 106,
            "set": 103,
            "error": 26,
            "message": 58,
            "in": 46,
            "ex": 27,
            "contributions": 21,
            "are": 10,
            "welcome": 126,
            "you": 129,
            "like": 54,
            "contribute": 19,
            "project": 81,
            "please": 73,
            "open": 67,
            "pull": 84,
            "proposed": 83,
            "changes": 14,
            "released": 88,
            "under": 122,
            "apache": 8
        },
        "idf_values": {
            "__numpy_array__": true,
            "data": [
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0
            ]
        },
        "params": {
            "analyzer": "word",
            "binary": false,
            "decode_error": "strict",
            "dtype": "<class 'numpy.float64'>",
            "encoding": "utf-8",
            "input": "content",
            "lowercase": true,
            "max_df": 1.0,
            "max_features": null,
            "min_df": 1,
            "ngram_range": [
                1,
                1
            ],
            "norm": "l2",
            "preprocessor": null,
            "smooth_idf": true,
            "stop_words": null,
            "strip_accents": null,
            "sublinear_tf": false,
            "token_pattern": "(?u)\\b\\w\\w+\\b",
            "tokenizer": null,
            "use_idf": true,
            "vocabulary": null
        }
    }
}